{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a8277b",
   "metadata": {},
   "source": [
    "Datensatz √∂ffnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231cebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movies.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56e7e3",
   "metadata": {},
   "source": [
    "Jahr als separates Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313381ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                        title  \\\n",
      "0        1                    Toy Story   \n",
      "1        2                      Jumanji   \n",
      "2        3             Grumpier Old Men   \n",
      "3        4            Waiting to Exhale   \n",
      "4        5  Father of the Bride Part II   \n",
      "5        6                         Heat   \n",
      "6        7                      Sabrina   \n",
      "7        8                 Tom and Huck   \n",
      "8        9                 Sudden Death   \n",
      "9       10                    GoldenEye   \n",
      "\n",
      "                                        genres  year  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  1995  \n",
      "1                   Adventure|Children|Fantasy  1995  \n",
      "2                               Comedy|Romance  1995  \n",
      "3                         Comedy|Drama|Romance  1995  \n",
      "4                                       Comedy  1995  \n",
      "5                        Action|Crime|Thriller  1995  \n",
      "6                               Comedy|Romance  1995  \n",
      "7                           Adventure|Children  1995  \n",
      "8                                       Action  1995  \n",
      "9                    Action|Adventure|Thriller  1995  \n"
     ]
    }
   ],
   "source": [
    "# Jahr extrahieren in neue Spalte 'year'\n",
    "df['year'] = df['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "\n",
    "# Klammerjahr aus dem Titel entfernen\n",
    "df['title'] = df['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea3f34b",
   "metadata": {},
   "source": [
    "# Prototyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e0d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deicc\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte gib 3 Filmtitel ein:\n",
      "‚ö†Ô∏è  Film nicht gefunden: j√∂kfdjls√∂kdajfdskjf\n",
      "\n",
      "üé¨ Empfehlungen:\n",
      "                                       title  \\\n",
      "61889                              UglyDolls   \n",
      "30639    Scooby-Doo! Mask of the Blue Falcon   \n",
      "23228                      The Magic Crystal   \n",
      "72526              Legends of Valhalla: Thor   \n",
      "49160  Puss in Book: Trapped in an Epic Tale   \n",
      "\n",
      "                                            genres  year  \n",
      "61889  Adventure|Animation|Children|Comedy|Fantasy  2019  \n",
      "30639  Adventure|Animation|Children|Comedy|Fantasy  2012  \n",
      "23228  Adventure|Animation|Children|Comedy|Fantasy  2011  \n",
      "72526  Adventure|Animation|Children|Comedy|Fantasy  2011  \n",
      "49160  Adventure|Animation|Children|Comedy|Fantasy  2017  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Daten vorbereiten\n",
    "df = pd.read_csv('movies.csv')\n",
    "df['year'] = df['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "df['title'] = df['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
    "df['year'] = df['year'].astype('Int64')\n",
    "\n",
    "# Genre-Vektoren (einmalig!)\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split('|'))\n",
    "genre_matrix = vectorizer.fit_transform(df['genres'])\n",
    "\n",
    "# Mapping von Titel zu Index\n",
    "title_to_index = {t.lower(): i for i, t in enumerate(df['title'])}\n",
    "\n",
    "# User Input (3 Titel)\n",
    "print(\"Bitte gib 3 Filmtitel ein:\")\n",
    "user_inputs = [input(f\"Film {i+1}: \").strip().lower() for i in range(3)]\n",
    "\n",
    "# Finde die Vektoren der eingegebenen Filme\n",
    "valid_indices = []\n",
    "for title in user_inputs:\n",
    "    if title in title_to_index:\n",
    "        valid_indices.append(title_to_index[title])\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Film nicht gefunden: {title}\")\n",
    "\n",
    "if not valid_indices:\n",
    "    print(\"‚ùå Keine g√ºltigen Filme eingegeben. Abbruch.\")\n",
    "else:\n",
    "    # Durchschnittlicher Genre-Vektor (mit Umwandlung zu dichten Array)\n",
    "    user_vector = genre_matrix[valid_indices].mean(axis=0).A.flatten()\n",
    "\n",
    "    # √Ñhnlichkeit zwischen User-Vektor und allen Filmen berechnen\n",
    "    similarities = cosine_similarity(user_vector.reshape(1, -1), genre_matrix).flatten()\n",
    "\n",
    "    # Top-N Empfehlungen (ausgenommen Eingaben)\n",
    "    top_n = 5\n",
    "    recommendations = similarities.argsort()[::-1]\n",
    "    recommendations = [i for i in recommendations if i not in valid_indices][:top_n]\n",
    "\n",
    "    print(\"\\nüé¨ Empfehlungen:\")\n",
    "    print(df.iloc[recommendations][['title', 'genres', 'year']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c561617e",
   "metadata": {},
   "source": [
    "Timemachine (separiert auch zwischen alte und neue Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ea73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deicc\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte gib 3 Filmtitel ein:\n",
      "‚ö†Ô∏è  Film nicht gefunden: title\n",
      "‚ö†Ô∏è  Film nicht gefunden: penis\n",
      "\n",
      "üé¨ Allgemeine Empfehlungen:\n",
      "                      title       genres  year\n",
      "40517        Cereal Killers  Documentary  2013\n",
      "17587  End of the Line, The  Documentary  2009\n",
      "17519         Metrobranding  Documentary  2010\n",
      "66622              Elephant  Documentary  2020\n",
      "66619  In My Father‚Äôs House  Documentary  2015\n",
      "\n",
      "üï∞Ô∏è Empfehlungen aus der Vergangenheit (vor 2010):\n",
      "                                            title       genres  year\n",
      "11877  Chronicle of a Summer (Chronique d'un √©t√©)  Documentary  1961\n",
      "48065                     Sapporo Winter Olympics  Documentary  1972\n",
      "48063       Sydney 2000: Stories of Olympic Glory  Documentary  2001\n",
      "48062    Salt Lake 2002: Stories of Olympic Glory  Documentary  2003\n",
      "48061           Lillehammer ‚Äô94: 16 Days of Glory  Documentary  1994\n",
      "\n",
      "üöÄ Empfehlungen aus der Zukunft (2010 oder sp√§ter):\n",
      "                                                  title       genres  year\n",
      "26135                                      Mulberry St.  Documentary  2010\n",
      "32344                                        Con Artist  Documentary  2010\n",
      "8392                                    The Real Miyagi  Documentary  2015\n",
      "25676               Mary Magdalene: Art's Scarlet Woman  Documentary  2017\n",
      "3037   Double Play: James Benning and Richard Linklater  Documentary  2013\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Daten vorbereiten\n",
    "df = pd.read_csv('movies.csv')\n",
    "df['year'] = df['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "df['title'] = df['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
    "df['year'] = df['year'].astype('Int64')\n",
    "\n",
    "# Zeilen ohne Jahr ausschlie√üen\n",
    "df = df.dropna(subset=['year'])\n",
    "\n",
    "# Genre-Vektoren (einmalig!)\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split('|'))\n",
    "genre_matrix = vectorizer.fit_transform(df['genres'])\n",
    "\n",
    "# Mapping von Titel zu Index\n",
    "title_to_index = {t.lower(): i for i, t in enumerate(df['title'])}\n",
    "\n",
    "# User Input (3 Titel)\n",
    "print(\"Bitte gib 3 Filmtitel ein:\")\n",
    "user_inputs = [input(f\"Film {i+1}: \").strip().lower() for i in range(3)]\n",
    "\n",
    "# Finde die Vektoren der eingegebenen Filme\n",
    "valid_indices = []\n",
    "for title in user_inputs:\n",
    "    if title in title_to_index:\n",
    "        valid_indices.append(title_to_index[title])\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Film nicht gefunden: {title}\")\n",
    "\n",
    "if not valid_indices:\n",
    "    print(\"‚ùå Keine g√ºltigen Filme eingegeben. Abbruch.\")\n",
    "else:\n",
    "    # Durchschnittlicher Genre-Vektor (mit Umwandlung zu dichten Array)\n",
    "    user_vector = genre_matrix[valid_indices].mean(axis=0).A.flatten()\n",
    "\n",
    "    # √Ñhnlichkeit zwischen User-Vektor und allen Filmen berechnen\n",
    "    similarities = cosine_similarity(user_vector.reshape(1, -1), genre_matrix).flatten()\n",
    "\n",
    "    # Top-N Empfehlungen (ausgenommen Eingaben)\n",
    "    top_n = 5\n",
    "    recommendations = similarities.argsort()[::-1]\n",
    "    recommendations = [i for i in recommendations if i not in valid_indices][:top_n]\n",
    "\n",
    "    print(\"\\nüé¨ Allgemeine Empfehlungen:\")\n",
    "    print(df.iloc[recommendations][['title', 'genres', 'year']])\n",
    "\n",
    "    # Time Machine: alte und neue Filme\n",
    "    old_mask = df['year'] < 2010\n",
    "    new_mask = df['year'] >= 2010\n",
    "\n",
    "    df_old = df[old_mask].reset_index(drop=True)\n",
    "    df_new = df[new_mask].reset_index(drop=True)\n",
    "\n",
    "    genre_old = genre_matrix[old_mask.values]\n",
    "    genre_new = genre_matrix[new_mask.values]\n",
    "\n",
    "    # √Ñhnlichkeiten berechnen\n",
    "    sim_old = cosine_similarity(user_vector.reshape(1, -1), genre_old).flatten()\n",
    "    sim_new = cosine_similarity(user_vector.reshape(1, -1), genre_new).flatten()\n",
    "\n",
    "    rec_old = sim_old.argsort()[::-1][:top_n]\n",
    "    rec_new = sim_new.argsort()[::-1][:top_n]\n",
    "\n",
    "    print(\"\\nüï∞Ô∏è Empfehlungen aus der Vergangenheit (vor 2010):\")\n",
    "    print(df_old.iloc[rec_old][['title', 'genres', 'year']])\n",
    "\n",
    "    print(\"\\nüöÄ Empfehlungen aus der Zukunft (2010 oder sp√§ter):\")\n",
    "    print(df_new.iloc[rec_new][['title', 'genres', 'year']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866eb499",
   "metadata": {},
   "source": [
    "# Code mit Tags\n",
    "Im folgenden Code werden Tags inkludiuert, da ist das folgende klar geworden.\n",
    "\n",
    "Manche Movies haben KEINE Tags und manche haben SEHR VIELE, das verursacht PROBLEMS. Wenn Users z.B. Inputs verwenden, welche keine Tags haben, dann werden vom Code Empfehlungen preferiert, die AUCH keine Tags haben. Das scheint nicht sinnvoll zu sein.\n",
    "\n",
    "Das Problem entsteht dadurch, dass Features \"Genre\" und \"Tags\" kombiniert werden, und dann das empfohlen wird, was am meisten Gemeinsamkeiten zwischen den Films hat. Sinnvoller w√§re, wenns eine gewisse Hierarchie geben w√ºrde. Beispielsweise, dass die Genres Wichtiger sind als Tags. Allerdings scheint es sinnvoller die Tags komplett zu ignorieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973387f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deicc\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitte gib 3 Filmtitel ein:\n",
      "‚ö†Ô∏è  Film nicht gefunden: f\n",
      "‚ö†Ô∏è  Film nicht gefunden: f\n",
      "‚ö†Ô∏è  Film nicht gefunden: f\n",
      "‚ùå Keine g√ºltigen Filme eingegeben. Abbruch.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Daten laden und vorbereiten\n",
    "# -----------------------------\n",
    "df_movies = pd.read_csv('movies.csv')\n",
    "df_tags = pd.read_csv('tags.csv')\n",
    "\n",
    "# Jahr extrahieren und Titel bereinigen\n",
    "df_movies['year'] = df_movies['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "df_movies['title'] = df_movies['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
    "df_movies['year'] = pd.to_numeric(df_movies['year'], errors='coerce')\n",
    "\n",
    "# Relevante Spalten aus Tags behalten und gruppieren\n",
    "df_tags = df_tags[['movieId', 'tag']]\n",
    "df_tags = df_tags.dropna(subset=['tag'])  # leere Tags entfernen\n",
    "tags_grouped = df_tags.groupby('movieId')['tag'].apply(lambda tags: '|'.join(tags.unique())).reset_index()\n",
    "tags_grouped.columns = ['movieId', 'tags']\n",
    "\n",
    "# Tags mit Movie-Daten kombinieren\n",
    "df = df_movies.merge(tags_grouped, on='movieId', how='left')\n",
    "df['tags'] = df['tags'].fillna('')  # Leere Tags auff√ºllen\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Feature-Vektorisierung\n",
    "# -----------------------------\n",
    "# Genres + Tags zu einem kombinierten Feature\n",
    "df['combined'] = df['genres'].fillna('') + '|' + df['tags']\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x: x.split('|'))\n",
    "combined_matrix = vectorizer.fit_transform(df['combined'])\n",
    "\n",
    "# Mapping Titel -> Index\n",
    "title_to_index = {t.lower(): i for i, t in enumerate(df['title'])}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Benutzereingabe\n",
    "# -----------------------------\n",
    "print(\"Bitte gib 3 Filmtitel ein:\")\n",
    "user_inputs = [input(f\"Film {i+1}: \").strip().lower() for i in range(3)]\n",
    "\n",
    "valid_indices = []\n",
    "for title in user_inputs:\n",
    "    if title in title_to_index:\n",
    "        valid_indices.append(title_to_index[title])\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Film nicht gefunden: {title}\")\n",
    "\n",
    "if not valid_indices:\n",
    "    print(\"‚ùå Keine g√ºltigen Filme eingegeben. Abbruch.\")\n",
    "else:\n",
    "    user_vector = combined_matrix[valid_indices].mean(axis=0).A.flatten()\n",
    "\n",
    "    # Jahr-Masken (nur Filme mit g√ºltigem Jahr)\n",
    "    valid_year_mask = df[\"year\"].notna()\n",
    "    old_mask = valid_year_mask & (df[\"year\"] < 2010)\n",
    "    new_mask = valid_year_mask & (df[\"year\"] >= 2010)\n",
    "\n",
    "    df_old = df[old_mask].reset_index(drop=True)\n",
    "    df_new = df[new_mask].reset_index(drop=True)\n",
    "\n",
    "    matrix_old = combined_matrix[old_mask.values]\n",
    "    matrix_new = combined_matrix[new_mask.values]\n",
    "\n",
    "    # √Ñhnlichkeiten berechnen\n",
    "    sim_old = cosine_similarity(user_vector.reshape(1, -1), matrix_old).flatten()\n",
    "    sim_new = cosine_similarity(user_vector.reshape(1, -1), matrix_new).flatten()\n",
    "\n",
    "    # Top-Empfehlungen (alte & neue)\n",
    "    top_n = 5\n",
    "    rec_old = sim_old.argsort()[::-1][:top_n]\n",
    "    rec_new = sim_new.argsort()[::-1][:top_n]\n",
    "\n",
    "    df['tags'] = df['tags'].fillna('no tags')\n",
    "\n",
    "    print(\"\\nüé¨ Empfehlungen (vor 2010):\")\n",
    "    print(df_old.iloc[rec_old][['title', 'genres', 'tags', 'year']])\n",
    "\n",
    "    print(\"\\nüé¨ Empfehlungen (ab 2010):\")\n",
    "    print(df_new.iloc[rec_new][['title', 'genres', 'tags', 'year']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a0aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
